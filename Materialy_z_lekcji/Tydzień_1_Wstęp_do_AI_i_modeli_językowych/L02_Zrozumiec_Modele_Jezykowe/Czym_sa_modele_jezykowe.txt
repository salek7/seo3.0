Cześć, witam Cię w kolejnej lekcji. W poprzedniej zapoznaliśmy się z historią modeli językowych. Jesteśmy już w 2025 roku. Pomówmy jeszcze przez chwileczkę o podstawach modeli językowych. I chciałbym Ci opowiedzieć, czym są modele językowe, jakie mają wyzwania, jak się poruszać w tym świecie, jak je rozpoznawać, jak je oceniać, tak żeby w kolejnych lekcjach płynnie poruszać się w tym świecie i dobierać tak model, żeby spełniał Twoje zarówno oczekiwania, jak i cele czy procesy biznesowe. Okej, pierwsza sprawa. Modele językowe nie mają kreatywności. Modele językowe zostały wytrenowane na zestawie danych. Często, gęsto te dane są nieaktualne i powiedzmy wiedza modeli językowych jest gdzieś odcięta w 2023, być może w 2024 roku, więc modele nie mają kreatywności żadnej. Modele, jeśli mają podyskać jakąkolwiek kreatywność, muszą być karmione w formie feedbackowej. Tak są tworzone leki, tak są tworzone nowe proteiny. Czyli jest coś przewidywane przez model językowy, weryfikowane i po prostu jakaś baza danych budowana. Natomiast co do zasady, one są, jakie są, nie mają kreatywności, przez co nie wytworzą nowych rzeczy. To są procesory językowe, które trzeba nakarmić. Będziemy to bardzo, bardzo szeroko omawiać w tym kursie. I dopiero wnioskować i wytwarzać, powiedzmy albo nowe rzeczy na podstawie karmienia, albo syntezować na podstawie karmienia, ponieważ co do zasady one po prostu są procesorami językowymi, które przetwarzają wejście, dając nam jakieś wyjście. Ok, jak działają modele językowe? Prosty wzór na model językowy. LLM, czyli Large Language Model, równa się Deep Learning plus dane i proces treningowy. Deep Learning, żebyś zrozumiał, to jest na tej zasadzie. Machine learning, masz dane, to jest twoje zadanie, wykonaj zadanie. Deep learning to są, masz dane, zrób coś z nimi. Czyli model po prostu dostaje ogromny korpus danych i po prostu się na nich uczy w sposób taki, że nikt mu nie dał tego zadania. Jak ma się uczyć. Skąd pochodzą dane? Bazy danych, organizacje typu Common Crowd, to jest taka organizacja, która w cudzysłowie ściąga cały internet na dyskietkę, zapisuje i można te dane, czy korpus internetu pozyskać. Książki, dokumenty, wszystko, na czym nie ma prawa autorskich i można pozyskać. Wasze strony internetowe, na szczęście moje też, więc jakby cieszymy się i tak dalej, i tak dalej. Czyli powiedzmy, wyobraźmy sobie gigantyczny, wielki odkurzacz, który jest w stanie wciągnąć cały internet, to tym właśnie jest AI w procesie treningowym. Na początku wciągnęli odkurzaczem cały internet i dali, masz, zrób coś z tym. W 2025 roku Elon Musk, powiedział, że jesteśmy w miejscu, w którym dane treningowe, te realne ze świata ludzkiego powiedzmy, skończyły się. Dlatego w tym momencie dochodzą również dane syntetyczne. Przedniej lekcji mówiłem ci o treningu samochodów autonomicznych. To właśnie są trenowane na danych syntetycznych. Jak to rozumiemy? Mamy zestaw danych, który tutaj widzimy przed sobą i na podstawie tego są tworzone syntetyczne dane, czyli AI tworzy sobie większy zestaw danych, na podstawie których jest dalej trenowany. No tak to działa. W związku z tym mamy kilka problemów. Okej, w tym roku, w 2025 problemy są coraz powiedzmy mniejsze albo są redukowane, ale ciągle występują i muszę Ci o tym powiedzieć, ponieważ z perspektywy SEO czy marketingu to jest najważniejsza rzecz, którą będziemy zarządzać w tym kursie. Czyli pierwsza sprawa. Nie do końca wiemy, jak to działa. Modele mają charakterystykę probabilistyczną, czyli z jakimś prawdopodobieństwem, ci odpowiadają. Nie do końca wiemy z jakim. Znaczy wiemy, jesteśmy w stanie sterować, ale musimy na tyle dobrze zasterować tym modelem, żeby na przykład uzyskać odpowiedni format albo odpowiednią odpowiedź, która nas interesuje, ponieważ jeśli nie, to model nam coś po prostu odpowie. Także sorry, ja się zajmuję tym powiedzmy profesjonalnie, też nie wiem. W zeszłym roku powstało badanie, które pokazywaliśmy, czyli ten AI Brain Surgery, tak to się dumnie nazywa, czyli naukowcy w jakiś sposób wzięli najmniejszy możliwy model na świecie i wykazali, że jeżeli zadają mu zadanie przetłumaczenia treści na język rosyjski, to jakiś element modelu, możemy sobie wyobrazić, to jak połączenia w mózgu zaczyna realizować to zadanie. Jeżeli temu samemu modelowi dają zadanie, powiedzmy, sumaryzacji treści, to zupełnie inna część tej sieci neuronowej zaczyna realizować to zadanie, więc troszeczkę możemy sobie to wyobrażać jak ludzki mózg na takiej zasadzie, że lewa półkula pełni inna funkcja niż prawa półkula, natomiast dwie są potrzebne, żebyśmy żyli. Szczęśliwie pojawiło się kolejne badanie. Poprzednie również stworzył Antropik. To badanie również stworzył Antropik. Chciałbym Ci pokazać krótki filmik, który omawia, do czego dochodzą naukowcy, jakie są wnioski i jak działa model językowy. Ciągle traktujemy to jako black box, czyli wsadzamy coś, wyjmujemy i w środku coś dzieje. Naukowcy próbują to opisać. Zapraszam Cię na krótki filmik, który troszeczkę nam rozjaśni, co się dzieje. Jest to filmik z 2025 roku. Także dwie minutki. Zapraszam. You often hear that AI is like a "black box." Words go in and words come out, but we don't know why it said what it said. That's because AIs aren't programmed, but trained. And during training, they learn their own strategies to solve problems. If we want AIs to be as useful, reliable, and secure as possible, we want to open up the black box and understand why they do things. Ale nawet nie jest bardzo pomocny to form logical circuits. Let's take a simple example where we ask Claude to write the second line of a poem. The poem starts, he saw a carrot and had to grab it. In our study, we found that Claude is planning a rhyme even before writing the beginning of the line. Claude sees a carrot and grab it and thinks of rabbit as a word that would make sense with carrot and rhyme with grab it. Then it writes the rest of the line. His hunger was like a starving rabbit. We look at the place that the model was thinking about the word rabbit, and we see other ideas it had for places to take the poem. We also see the word habit is present there. Our new methods allow us to go in and intervene on this circuit. In this case, we dampen down rabbit as the model is planning the second line of the poem, and then ask Claude to complete the line again. His hunger was a powerful habit. We see that the model is capable of taking the beginning of a new poem and thinking of different ways it could complete it and then writing it towards those completions. The fact we can cause these changes to occur well before the final line is written is strong evidence that the model is planning ahead of time. This poetry planning result, along with the many other examples in our paper, only makes sense in a world where the models are really thinking w ich własnej way, about what they say. Just as neuroscience helps us treat diseases and make people healthier, our longer-term plan is to use this deeper understanding of AI to help make the models safer and more reliable. If we can learn to read the model's mind, we can be much more confident it is doing what we intended. You can find many more examples of Claude's internal thoughts in our new paper at anthropic.com slash research. No właśnie, tak jak słyszeliśmy, model to jest ciągle black box, który, tam było bardzo ważne zdanie, nie został zaprogramowany, tylko został wytrenowany w taki sposób, że sam rozwiązuje problemy. Naukowcy wykazali, że modele są w stanie nie tylko przewidywać następny token, mówiłem o tym w pierwszej lekcji na przykładzie Financial Timesu, ale są w stanie planować to, co się wydarzy w przyszłości, czy w następnym zdaniu. Tam był przykład z rymami, habit, rabbit, okej? Więc też musimy zapanować troszeczkę nad tym, jak on zaplanuje, to co ma tam dalej nam odpisać, prawda? To będzie Damian pokazywał w swojej części dotyczącej prompt engineeringu właśnie, jak nad tym zapanować. No i co? Na dzień dzisiejszy tyle wiemy o modelach językowych, więc przewidywanie następnego tokenu, planowanie i trening, który po prostu jest taki, że model sam się uczył i sam rozwiązywał problemy. W związku z tym mamy największe wyzwanie SEO, halucynacje, ponieważ to jest ciągle prawdopodobieństwo i ciągle planowanie z jakimś prawdopodobieństwem następnego słowa, tokenu, rymu, jak na przykładzie Rabbity Habit i to jest bardzo ciekawe. największe wyzwanie. Jeżeli dotychczas powiedzmy, szedłeś do chat-a GPT i pisałeś, napisz mi arcykuł na temat chwilówki, to na pewno dostawałeś ten arcykuł, oczywiście. Natomiast z dużą pewnością nie działał, prawda? Powiedzmy, Google nie było zainteresowane tym arcykułem w żaden sposób i przez ostatnie miesiące serwisy, które jakby nie rozwiązały, czy osoby nie rozwiązały problemu halucynacji, no jakby utraciły widoczności i będą tracić przy kolejnych kurach update'ach, więc w tym kursie bardzo mocno się pokłonimy. I zobaczcie coś ciekawego. To jest bardzo ciekawa rzecz dotycząca halucynacji. Po prawej stronie widzimy Gemini 2.0 Flash. Jest to model, który zapewne rządzi AI Overview w Polsce i na świecie. Dlaczego? No bo jest najtańszy, najszybszy, bardzo dobry przy okazji, ale widzimy, że bez dostarczenia danych charakteryzuje się poziomem halucynacji 60%. Czyli wyobraź sobie, że 60% twoich treści potencjalnie, jeżeli używasz Gemini 2.0 Flash, może być shalucynowane. No i zobacz, jeżeli oni mają wyzwanie odpowiadania na świecie ludziom w AI Overview i tworzenia tych wyników AI-owych, ale mają taką charakterystykę halucynacji, no to jest to gigantyczny problem. Gdzie tutaj mamy czata? No powiedzmy GPT-4O. Jest to najpopularniejszy model czatowy i mocno wykorzystywany w kontekstach SEO. 57% halucynacji. Czyli co drugie zdanie może być fałszywe w tym przypadku. Ale zobacz jedną bardzo ważną rzecz. Powiedziałem już. chyba w poprzedniej lekcji, że modele są to procesory językowe, być może w tej. Jeżeli ten sam model Gemini Flash, który charakteryzuje się 60% halucynacją, zostanie nakarmiony, ten sam model charakteryzuje się halucynacją 0.7, karmieniem modeli językowych. I tego właśnie poszukuje Google. Google wie, że sam model co do siebie, sam black box, który wystawia nam, halucynuje. Jak zostanie nakarmiony faktycznymi danymi z Twojej strony internetowej, z mojej i tego właśnie poszukuje AI Overview, co będziemy bardzo szczegółowo omawiać w tym kursie, ten sam model już zbliża się do zera, jeśli chodzi o poziom halucynacji. Więc da się ten problem rozwiązać i da się skutecznie budować content z wykorzystaniem modeli językowych, jak zostaną nakarmione w taki sposób, jak Google karmi AI Overview. 0,7% po nakarmieniu. Przypominam, 60 bez. Także to jest ważne, bardzo ważne i musimy to zaadresować w tym kursie i zrobimy to. Kolejny problem. Stronniczość. No, to wynika z tego, że modele nie zostały na przykład wytrenowane na danych polskich. Jeżeli dane polskie stanowią jakiś korpus treningowy, no to jest to pewnie jakiś procent albo poniżej jednego procenta po prostu gdzieś coś po polsku się znalazło. Przez co będą stronnicze zapewne do języka angielskiego. No bo tam pewnie korpus językowy jest absolutnie największy. szczęśliwie pewnie niestronnicze do rosyjskiego, bo pewnie tam nie było języka rosyjskiego w procesie treningowym, albo był w małym stopniu, więc jakby to jest taka dobra informacja. Ale dlaczego to jest problem? Jeżeli pójdziesz do czata i każesz mu napisać artykuł na jakiś temat, to z dużym prawdopodobieństwem zostanie napisany z perspektywy amerykańskiej. Ze stuprocentową pewnością zostanie napisany z interpunkcją amerykańską, typu na przykład duża litera po dwukropku. Listowanie zupełnie inaczej się tworzy w języku polskim niż w języku amerykańskim. W języku amerykańskim czy w angielskim, co do zasady. Pierwszy element listy jest w dużej litery, drugi w dużej litery, trzeci w dużej litery i ostatni z dużej litery w listowaniu. W języku polskim, i to mi zawsze zwracali proofreaders czy edytorzy językowi, profesjonaliści w języku polskim, że tylko pierwszy element w języku polskim jest w dużej litery i kończy się przecinkiem, każdy następnie z małej litery i kończy się kropką. W języku angielskim tak się nie dzieje. Tak więc jeżeli pójdziesz do wczoraj, przepraszam, nie definiując zależności językowych, czy sposobu pisania, otrzymasz tekst sformatowany po amerykańsku po prostu. I wystarczy na niego spojrzeć, już wiesz, że on jest z czata, więc jakby to jest właśnie stronniczość i też będziemy tym zarządzać. Niedeterministyczne zachowanie. O tym już mówiłem. Model ci coś odpowie. Z jakimś prawdopodobieństwem trzeba tym zarządzić i bezpieczeństwo danych. To jest też ogromne wyzwanie modeli językowych na dzień dzisiejszy, bo twoje dane są wysyłane gdzieś. Na przykład do Stanów Zjednoczonych. Pewnie tam nie ma RODO takiego, jakiego jest w Unii Europejskiej. I OpenAI obiecuje nam, ale twoje dane nie będą brane w procesie treningowym pod uwagę. No okej. Tak jest w API. Jeżeli powiedzmy dzwonisz bezpośrednio, rozmawiasz z modelem. Natomiast w czacie, jak sobie czatujesz, Twoje dane mogą być brane pod uwagę w kolejnym procesie treningowym. Czat czasami ma te takie okienka feedbackowe, gdzie pytać się, w jaki sposób ci odpowiedział, co jest lepsze, co jest gorsze. I wyobraź sobie sytuację. Chcesz robić jakieś projekcje finansowe w swojej firmie, wrzucasz dane finansowe do czata, bo chcesz sobie coś policzyć, chcesz sobie policzyć EBITDA czy tam inne historie. Twoje dane są wzięte pod uwagę w procesie treningowym, bo tak się może wydarzyć. A ja później przychodzę i piszę, podaj mi wynik finansowy twojej firmy. No i na podstawie danych finansowych, które ty sobie trenowałeś, EBITDA czy tam jakieś forecasty finansowe, no możemy się dowiedzieć ile zarobiłeś pieniędzy, nie? Więc jakby tutaj musimy uważać, rozwiązanie są modele open source'owe, które również będziemy omawiać w tym kursie, ponieważ na dzień dzisiejszy jesteś w stanie postawić model nawet na swoim laptopie czy w swojej firmie. Bardzo dobry model i być w pełni bezpieczny. Możesz też wybrać firmy, które działają na terenie Unii Europejskiej, są trochę lepiej regulowane. Oczywiście są też firmy chińskie, no i tam już po prostu nie wiemy, co się z tym wydarza. Co do zasady brak pamięci? To jest kolejne wyzwanie modeli językowych. Jeżeli rozmawiasz z modelem językowym w sposób, powiedzmy, profesjonalny przez API, tworzysz proces, on nie ma pamięci, on jest jaki jest, on to jest black box. Wsadzasz, wyjmujesz, wsadzasz, wyjmujesz. Przychodzisz jutro i on nie pamięta, o czym z tobą rozmawiał ostatnio. Też będziemy tym zarządzać, tak żeby modele zyskały pamięć. Oczywiście, systemy czatowe typu chat GPT, Klode, Grok, one... wewnętrznie budują sobie pamięć w środowisku czatowym. To się zaczyna dziać, pamiętają twoje konwersacje, pamiętają kontekst, możesz zarządzić to projektowo, pokażę ci to w następnych lekcjach. Natomiast one działają na takiej zasadzie, że to jest pamięć w narzędziu. To nie jest pamięć modeli, bo model jest jaki jest, jest czarnym skrzynką. Pamięć jest w narzędziu czata, czyli właśnie oni obudowali go pamięcią. W tym kursie również pokażemy ci, jak taką pamięć zbudować sobie wewnętrznie. Kontekst window. W 2024 roku był to ogromny problem. W 2025 roku, zgodnie z naszymi przewidywaniami, z moimi przewidywaniami i Damiana, kontekst window się rozszerza, przestaje to być wyzwanie. W 2024 roku 128 tysięcy tokenów, czyli wyzwanie ciągle, bo nie możesz wsadzić ile chcesz. W tym roku jesteśmy na poziomie miliona tokenów, więc można tam wsadzić naprawdę bardzo dużo, ale pamiętaj, że to jest ciągle limitowane. To nie jest tak, że wsadzisz tam ile chcesz, masz limit. Więc ten kontekst window też jest istotny i często jest limitowana odpowiedź, czyli dobra, ok, w 2025 roku wsadzisz milion tokenów, czy pewnie dużo książek na przykład i ok, masz myśl, a ciągle odpowiedź jest limitowana po drugiej stronie na przykład do 16 czy 32 tysięcy tokenów, więc to nie jest tak, że ci napiszę książkę na jeden raz. Tutaj z tego wynika. No i parametry. Porozmawiamy o parametrach. To już nie są wyzwania, to nie są problemy, natomiast tak są opisywane modele językowe parametrami. Zrozummy to. Parametry, tak jak mówiłem o tym AI Brain Surgery, to jest właśnie to, że lewa półkula odpowiada za coś, prawa półkula odpowiada za coś. Możemy sobie wyobrazić to jak połączenia w mózgu, czy połączenia jakiejś tam sieci, mniej więcej. Im więcej parametrów, tym mądrzejszy model, co prezentuje następny slajd. Działa to mniej więcej na takiej zasadzie. Są małe modele, teraz raz pokażę, one mają mało parametrów i są duże modele. Małe mniej potrafią, bo mają mniej połączeń mózgowych, duże modele, teraz mówi się o modelach, które mają powiedzmy 600 miliardów parametrów, czyli 600, wyobraźmy sobie to jako połączeń mózgowych, po prostu potrafią dużo więcej. I widzimy, tutaj model właśnie rośnie i w momencie, kiedy osiąga powiedzmy te 540 miliardów parametrów, nagle on umie tłumaczyć żarty albo jakieś tam logiczne zadania, czego mały model nie umiał. Więc jakby tak się modele dzielą. Małe dure. Do tego jeszcze przejdziemy. Każdy model językowy jest opisany swojego rodzaju benchmarkami. To też się zmienia w czasie, bo okazuje się, że benchmarki, którymi modele językowe były opisywane jeszcze w zeszłym roku, przestają być aktualne. Dlaczego? Bo wszystkie modele zaczęły osiągać górne granice typu 89, 91, 95. nie było tego miejsca już od 91% na przykład do 100%, żeby rosnąć, dokładnie dywersyfikować, opisywać ten modelem, bo już są takie dobre po prostu, ale powiem Ci, jak dotychczas się to opisywało, bo jest to całkiem istotne. Kilka kluczowych benchmarków. Multitask Language Understanding, Graduate Level Google Proof, Math Work Problem, Evil Coding, Multilingual Grade School Math, Discrete Resonning Over Paragraph. To są przykładowe benchmarki. Więc większość modeli językowych, z którymi mamy do czynienia w 2025 roku, w każdym z tych benchmarków osiąga maksymalne wartości. Co tu jest istotne? To są zadania tekstowe, to są multiselekty często gęste, na przykład ten discrete reasoning over paragraph, typu model dostaje ileś paragrafów treści i ma na tej podstawie wnioskować. czy ten Human Evil Code Generation podświetle go. Jest to na przykład benchmark, który mówi o tym, jak dobrze model koduje. Albo jakieś zadania matematyczne, co widzimy wyżej. Albo jakieś zadania właśnie wnioskowania po języku i tak dalej. To są zawsze zadania tekstowe. W 2025 roku ja ten kurs nagrywam, tę lekcję nagrywam w zdaje się 24 bądź 5, to dzisiaj jest 25, 25 kwietnia. Dwa tygodnie temu dostaliśmy również informacje, że aktualne modele językowe rozwiązują test Turinga. Test Turinga działa w taki sposób, że jest powiedzmy AI, czy komputer, nazwijmy to po prostu komputerem i człowiek i sędzia. Sędzia ludzki, człowiek. I komputer daje odpowiedź i człowiek daje odpowiedź, a sędzia próbuje zgadnąć, co zostało wygenerowane przez komputer. No w tym roku już jakby test Turinga modele językowe zdają, człowiek się pomylił, zdaje się, w 75% przypadków na korzyść komputera. I każdy model jest opisany takimi benchmarkami, ale jest jeden najważniejszy, który wysuwa się na prowadzenie. Dlaczego? Ponieważ często gęsto jest wyścig między firmami, że o, ja mam taki ten human evil, ja mam coś takiego, ja mam coś takiego, ja mam coś takiego i przez te modele językowe zostały trenowane pod benchmarki po prostu na zasadzie, okej, trenujemy cię na konkretny zestaw zadań, żeby być wysoko w benchmarkach, ale one niekoniecznie są takie po prostu super, realnie. Dlatego powstał Humanity Last Exam. Coś takiego. To jest bardzo, bardzo ciekawa sprawa, bo tak jak powiedziałem, benchmarki już nie dojeżdżają. Nie ma miejsca na ocenę modeli, ponieważ no tak jak masz 95% na przykład w jakimś benchmarku, no to no to nie ma miejsca, żeby oceniać. W związku z tym naukowcy z całego świata się powiedzmy skrzyknęli, to był taki program finansowany duży i naukowcy z Politechnik, z Uniwersytetów, z Akademii z całego świata wymyślali zadania logiczne, na które nie da się odpowiedzieć w jeden prosty sposób. Jest to zestaw, powiedzmy, nie pamiętam ilu, ale pewnie, nie wiem, 200-300 pytań. Naukowcy za stworzenie takich pytań byli wynagradzani finansowo i to są pytania klasy takiej, że model musi się bardzo mocno zastanowić, wnioskować, poszukać informacji na temat tego, żeby rozwiązać zadanie. Możemy sobie wyobrazić jakieś odjechane zadanie, na przykład z fizyki kwantowej, jakiś powiedzmy, nie wiem, ruch elektronów, w jakiejś tam próżni, w jakiejś tam studni potencjałów, takie zadania miałem na mojej Politechnice na przykład. No tego się nie da w proze odpowiedzieć po prostu, bo to jest tak trudne. I właśnie tak wygląda Himanetielas exam. I modele na szczęście zaczynają być już tak opisywane. To nam troszeczkę dywersyfikuje jakby zrozumienie i to jest przykład Gemini 2.5 Pro. Obecnie chyba najlepszy model na świecie. No, czy nie wiem, kiedy oglądasz tą lekcję, być może już się dużo zmieniło, bo co tydzień są ruchy. Modele osiągają teraz w tym Humanity Lasexam poziom 18%, co do zasady prawie 19% poprawnych odpowiedzi na te super trudne pytania logiczne wymyślone przez naukowców i to powoduje, że jest dużo miejsca jeszcze na ten wzrost. Co ważne, to są modele, one same w sobie, na poziomie swojej wiedzy osiągają takie takie wyniki, więc jeżeli chcesz ocenić model językowy w sposób niezmanipulowany, no to właśnie patrzymy na Humanity Last Exam jako ten kluczowy benchmark. 18-8% 25 kwietnia. Tak to wygląda. Na pewno to się będzie rozpędzać. Też jest ciekawa nazwa. Humanity Last Exam. Ostatni egzamin ludzkości. Czyli co? Jak osiądniem 100%, to co będzie? No nie wiem, zobaczymy. Istnieją areny, takie leaderboardy. Możesz sobie wpisać w Google chatbot, arena, chatbot, leaderboard, AI leaderboard i oni te wszystkie benchmarki unifikują do jakiegoś jednego skoru, do jednej metryki. W ten sposób też jest dosyć łatwo się poruszać, no jak widzimy właśnie ten Gemini 2.5 Pro, który osiąga to 18-8% w Humanity Last Exam jest najlepszy na dzień dzisiejszy na świecie, więc możemy sobie w ten sposób łatwo ocenić, że okej, to jest dobry model do moich zadań albo najlepszy ogólnie, jeżeli chcemy to zrobić w klasy no-brainer. Ten jest najlepszy, bierzemy go. Możemy oceniać na zasadzie właśnie, na przykład jeżeli mamy konkretne zadania, bo jeden sobie poradzi w logice, czy w rezoningu, okej, to robimy to w ten sposób. Jeżeli mamy wyzwanie na przykład programowania, no to już spójrzmy na ten Human Evil, że na przykład, nie wiem, Cloud 3.7 Sonnet na dzień dzisiejszy będzie w tym najlepszy, no bo się po prostu w tym specjalizuje, jakby w zeszłym roku tego nie widzieliśmy. W 2025 roku widzimy zdecydowaną specjalizację modeli w jakimś tam kierunku, albo firm wręcz, OK, Antropic wyspecjalizuje się w programowaniu, a na przykład OpenAI będzie się specjalizować w czymś innym, takie rzeczy obserwujemy. Dobra, podzielmy te modele w jakiś tam sposób, żebyśmy lepiej się odnaleźli w tym świecie i umieli doskonale w nim poruszać. Przede wszystkim są modele małe, to są te ilości parametrów, które modele mają, czyli modele małe będą potrafić troszkę mniej, ale do niektórych zastosowań mogą być doskonałe. Małe modele też są dużo tańsze w utrzymaniu, dużo tańsze w promptowaniu, więc jakby to jest istotne, że na przykład, ok, mamy ogromne zadanie. Wyobraźmy sobie zadanie, nie wiem, klasyfikacji polskiego internetu. No, brzmi jak drogo. Ale mały model może się okazać do tego doskonały, żeby na przykład skategoryzować strony internetowe, bo to potrafi i będzie to na przykład 10 razy tańsze niż w przypadku modeli dużych. Takim najlepszą reprezentacją na dzień dzisiejszy małego modelu jest Gemma 3 od Google. Jest to model open source'owy, który możesz ściągnąć na swój komputer. tuneować, dostrajać jest za darmo i to jest najlepsza reprezentacja małego modelu, który jest świetny. Zobacz, to są właśnie te benchmarki i widzisz, już masz my tutaj ten score, jeden, tę zunifikowaną wartość. Nie mówimy, że to ma 40 benchmarków, nie, mamy jeden score i model, który ma 27 miliardów parametrów. To widzimy na dole, ja mam taki fajny pilot, pokażę ci to, to patrzymy tutaj, gdzie to jest, o, 27 miliardów parametrów. Praktycznie dorównuję modelowi, który ma 371 miliardów parametrów. Oczywiście są jakieś drobne różnice w tym skorze, ale małe modele zaczynają powiedzmy dojeżdżać w tym przykładzie DeepSea i to jeszcze DeepSea reasoningowego, o którym zaraz będę mówić, a raczej o reasoningu, więc jakby nie zamykajmy się na małe modele, no najlepsza na świecie jest na dzień dzisiejszy gamma. Jak oni to osiągnęli? Oni osiągnęli to w procesie kwantyzacji. Nie będziemy dokładnie tego omawiać w tym kursie, natomiast mniej więcej chodzi o to, że w trakcie treningu model był kwantyzowany, czyli powiedzmy liczby zmienną przecinkowe, tam 32-bitowe zostały na 8 bitów. Sorry. Po prostu był zmniejszany na tyle skutecznie, że nie utracił jakości, miał mniejszej ilości połączeń w mózgu, więc nie zamykamy się na małe modele. Gemma jest najlepszym przykładem, że warto je brać pod uwagę do jakichś zadat. No i modele duże. Modele duże, no to są te wszystkie, które widzimy. O3, O4, GPT-4O, Sonety, Gemini, to są modele duże. One mają setki tysięcy, setki miliardów parametrów. I jak rozpoznajemy duży, mały? Pokażę Ci. To jest bardzo proste, ale jak chcesz się poruszać w tym świecie, musisz to wiedzieć. Zawsze model jest opisany w ten sposób. 1B, 1 miliard parametrów, 27B to jest 27 miliardów parametrów. W ten sposób są opisywane, więc jeżeli musisz wybrać sobie model do swojego zadania, no to możesz w ten sposób, właśnie jak Ci pokazałem, zweryfikować jego jego rozmiar. Niektórzy producenci modeli językowych nie podają rozmiaru, na przykład OpenAI nie podaje rozmiaru, bardziej piszą mini, czyli GPT-4-O duży, GPT-4-O mini mały. Także tak możemy się poruszać w tym świecie, a ten 4-O mini jest też również bardzo ciekawy. Komercyjne i open source'owe. Komercyjne płacimy, są pozamykane OpenAI, Gemini, ale Gemma jest już od Google open source'owa, czyli możemy ściągnąć na swój komputer i po prostu sobie zainstalować w swojej organizacji, zapewnić bezpieczeństwo danych, zoptymalizować koszty. Będą na ten temat kolejne lekcje. Modele są również opisywane w ten sposób. Czat i Instruct. Czat, model skonfigurowany, żeby z Tobą rozmawiać, wymieniać opinie, czatować, odpowiadać Ci. Model Instruct jest to model instrukcyjny, który porusza się po Twoich instrukcjach tam zrealizować zadanie powiedzmy profesjonalne. Żeby Ci to lepiej wytłumaczyć. I to jest najczęstszy błąd, jaki podpieniają ludzie, którzy na przykład idą w świat open source'u. Wybierają sobie jakiś model, powiedzmy Lame, czy whatever sobie wybierają, i wybierają model czatowy. I tam chcą sobie zrobić na przykład keyword research albo jakąś ekstrakcję. No to się nie wydarzy, bo ten model jest skonfigurowany do rozmowy z Tobą, więc wymieni opinię z Tobą na temat keyword research'u. Model instrukcyjny jest to model profesjonalny, więc w ten sposób możemy jeszcze modele rozróżniać, jeżeli chcemy się lepiej poruszać w tym świecie. No i zobacz, tak też są opisywane. Ta stara lama, tutaj co ją widzimy z zeszłego roku jest 8b, czyli czatowa. Jak nie ma napisać czat, to jest czatowa zazwyczaj. No instrukcyjna, czyli skonfigurowana do wykonywania instrukcji. Więc jeżeli nie ma tutaj czata, no to to będzie czatowe. Co prawda w tym roku już coraz więcej się mówi o takich modelach uniwersalnych, ale ciągle chciałem Ci to powiedzieć, żebyś umiał się poruszać w tym świecie. Okej. Mamy rozwój modeli wizyjnych. Modele już powiedzmy widzą. Modele wnioskują po tym, co widzą. W 2025 roku możesz rzucić zdjęcia i kazać modelowi na przykład wnioskować, co tam się znajduje na tym zdjęciu, jak coś zmienić, albo rozmawiać ze zdjęciami. Pokażę Ci bardzo fajną lekcję na koniec tego panelu tego tygodnia dotyczącą notebook LM. Co tam zrobiliśmy właśnie z wykorzystaniem tej wizyjności, tego, że model widzi. No i najważniejsze, modele reasoningowe. Tak też się dzielą modele. Nie wszystkie mają funkcję wizji, ok? Nie wszystkie mają funkcję reasoningu, czyli tego myślenia, przemyśliwania tematu, rozbijania tematu na małe części, w myśl zasady, dziel i rząd, czyli podziel duży problem na zestaw małych problemów, suma małych problemów stanowi duży problem. Tak działają modele rezonningowe, to są te właśnie IQ 132, czy też Gemini, którego pokazywałem. Tak też dzielimy modele. I zobacz, to jest ten leaderboard, który Ci pokazałem wtedy w kontekście tego ArenaScore, a teraz jakby się przyjrzeć, najlepsze modele na świecie właśnie mają tą charakterystykę rezonningową. Czy coś pominąłem? Nie. Wszystkie, które zaznaczyłem, no to na dole, O4, O1 również są rezonningowe. Czy mają zastosowania PSEO? Mają. Ogromne, na przykład do tworzenia nagłówków, do filtrowania nagłówków, do ustawienia hierarchii nagłówków, do jakiejś logiki, treści i tak dalej. Do generowania treści, no nie za bardzo, ale do przygotowania wsadu pod generowanie treści, w pełności tak, to pokażę Ci również w tym kursie, mają gigantyczne zastosowanie dla programistów. Ponieważ programiści mają problemy logiczne właśnie, albo mają jakiś kod, który trzeba, nie wiem, napisać jakieś bardzo skomplikowane zapytanie do bazy danych, czy coś takiego. Tam znajdują super zastosowanie właśnie modele klasy rezonningowej. No i powoli zbliżając się do SEO, chociaż SEO będzie za jakiś czas w tym kursie, jakie mamy wyzwania? Po stronie modeli językowych mamy wyzwanie halucynacji, wyzwanie właśnie biasu, czyli stronniczości, mamy problemy z danymi, a raczej z danymi historycznymi i ok. Jeśli chodzi o wyzwania SEO, znaczenie danych historycznych. Coraz bardziej w SEO Google bierze pod uwagę dane historyczne i sygnały ludzkie. Jest to potwierdzone przed kongresem amerykańskim, jest to potwierdzone w Google Leaków, że Google bierze to pod uwagę. No i teraz my, jako specjaliści SEO, czy też osoby, które chcą być, nie wiem, wysoko w Google, pewnie mają wyzwanie, jak na treści AI zdobyć dane historyczne, skoro, czy nikt nie chce tej treści czytać, albo mało czytać, albo treść jest shalucynowana, no to jak na treści shalucynowanej, czy niskiej jakości ma pozyskać pozytywne dane historyczne, kiedy cały internet jest rozpędzony w Polsce od, nie wiem, 15-20 lat, już te dane historyczne ma. Ogromne wyzwanie ze strony SEO. Po stronie SEO będziemy również tym zarządzać. Kolejne. Inflacja treści. Treści w internecie jest po prostu za dużo. Jeżeli potrzebujesz usmażyć naleśniki, wystarczą ci dwa przepisy. Jeden z wodą mineralną gazowaną, drugi bez wody mineralnej gazowanej zazwykłą. Na przykład. Co do zasady tyle. To jest taki przykład, który zawsze podaję. Po prostu treści jest za dużo, treści jest trochę za darmo. Ekonomia treści jest taka, że kurczę, cena idzie do zera, więc przestaje być po prostu copywriting czy treść jakimś gigantycznym wyróżnikiem, jeśli mamy jeszcze modele językowe, które mają wyzwania halucynacji, no to jest to chyba jedno z największych wyzwań, które stoi przed specjalistami SEO i w tym kursie również tym będziemy zarządzać i koszt przetwarzania. To wynika bezpośrednio z inflacji treści, bo Google za każdą twoją stronę internetową, za każdy nie wiem, crawl, indeksację płaci. Więc trzeba sobie zadać pytanie, dlaczego ma zapłacić za treść z czata GPT, która ma halucynacje, inne problemy, albo masową publikację treści, dlaczego ma zaindeksować. No i właśnie obserwujemy w tym roku problemy z indeksacją, jakby nie jest przewagą konkurencyjną masowe generowanie treści po prostu w czacie, bo to fajnie, ale cała konkurencja to robi, albo wpadł na ten genialny pomysł, że tak będzie budować przewagi, a Google za to nie chce płacić, tym również zarządzimy w tym kursie w kolejnych tygodniach dotyczącym kontentu. No i koniec. Co się dzieje? AI Search. Musimy myśleć o w jednej strony wyszukiwarkach przyszłości, ale one trochę już istnieją. Nie wszystkie funkcje są jeszcze w pełni dostępne w Polsce, no ale tak może wyglądać wyszukiwarka produktowa na świecie. No tak robi to Perplexity i tak to będzie za jakiś czas wyglądać również w Polsce, w Google, więc pewnie to jest doskonały moment, żeby się zastanowić, jak tam się znaleźć w przyszłości. O tym również opowiemy w tym kursie. No i to, co stało się faktem kilka tygodni temu, czyli AI overview, no AI już jest w searchu, prawda? Google już odpowiada bezpośrednio w wynikach wyszukiwania. Gigantyczne wyzwanie SEO, żeby A, tam się znaleźć, B, żeby odebrać z tego jakiś ruch, zoptymalizować starą treść, na przykład inflacja treści. Pokaż kotku, co masz w środku. Jakbym zadał Ci pytanie, co jest na Twoim blogu 5 lat temu, to pewnie nie wiesz. Więc na tym będziemy się również zastanawiać i pokazywać, jak tam się znaleźć, jak to działa. Bo zobacz, z jednej strony Google zabierze Ci ruch, zabierze. Są badania ze Stanów. 30-37% CTR-u, czyli ruchu z AI Overview. ale masz narzędzie, które pozwala Ci rosnąć 10 razy szybciej, więc jakby też sobie pozastanawiamy się na ten temat w tym kursie, w kolejnych lekcjach. No i tyle. Zapraszam Cię do kolejnych lekcji. W kolejnej lekcji pokażę Ci podstawowe narzędzia, jak się po nich poruszać, co tam jest istotne, jakie są fajne funkcje, jak się odnaleźć w tym świecie. I na końcu podsumuję mój prywatny ranking, czego ja używam i co Ci polecam. Do zobaczenia. Cześć. 
# Materiały do Tygodnia 1: Wstęp do AI i modeli językowych

Ten katalog zawiera materiały dodatkowe do lekcji z pierwszego tygodnia kursu SEO 3.0, wprowadzającego w świat sztucznej inteligencji i modeli językowych.

**Uwaga:** Wszystkie datasety używane w kursie są dostępne w centralnym katalogu [`../Datasety`](../Datasety).

---

## Lekcja: Historia modeli językowych

W tej lekcji przyglądamy się ewolucji technologii rozumienia języka naturalnego, od wczesnych koncepcji jak Word2Vec, przez Sequence-to-Sequence, aż po rewolucyjną architekturę Transformerów. Analizujemy, jak działają Transformery (tokenizacja, embedding, self-attention) na przykładzie materiałów Financial Times i omawiamy kluczowe momenty w rozwoju AI, w tym pojawienie się BERT i GPT. Lekcja zawiera również aktualizację dotyczącą gwałtownego przyspieszenia w rozwoju AI, multimodalności i przyszłości związanej z agentami AI i robotyką.

*   **Link do lekcji na platformie:** [Obejrzyj lekcję na SensAI Academy](https://learn.sensai.academy/next/public/lesson/252)
*   **Notatka z lekcji:** [./Lekcja_Historia_Modeli_Jezykowych/Notatka_z_lekcji.md](./Lekcja_Historia_Modeli_Jezykowych/Notatka_z_lekcji.md) - Szczegółowy przewodnik po historii modeli językowych, działaniu Transformerów i najnowszych trendach w AI.

---

## Lekcja: Zrozumieć modele językowe

W tej lekcji zagłębiamy się w podstawy działania dużych modeli językowych (LLM). Omawiamy, czym są (a czym nie są), jak przebiega ich trening (Deep Learning, dane treningowe, dane syntetyczne) oraz jakie są ich główne wyzwania: natura "czarnej skrzynki", halucynacje (kluczowe dla SEO), stronniczość, niedeterministyczne zachowanie, bezpieczeństwo danych, brak pamięci i ograniczenia okna kontekstowego. Przyglądamy się również metodom oceny modeli (parametry, benchmarki tradycyjne i nowoczesne jak Humanity Last Exam, areny) oraz ich kategoryzacji (małe/duże, komercyjne/open source, chat/instruct, wizyjne, reasoningowe). Na koniec omawiamy wyzwania dla SEO w erze AI i przyszłość wyszukiwania (AI Overview).

*   **Link do lekcji na platformie:** [Obejrzyj lekcję na SensAI Academy](https://learn.sensai.academy/next/public/lesson/253)
*   **Notatka z lekcji:** [./Lekcja_Zrozumiec_Modele_Jezykowe/Notatka_z_lekcji.md](./Lekcja_Zrozumiec_Modele_Jezykowe/Notatka_z_lekcji.md) - Kompleksowe omówienie podstaw LLM, ich działania, wyzwań, oceny i kategoryzacji w kontekście 2025 roku.

---

## Lekcja: Podstawowe narzędzia AI

W tej lekcji dokonujemy przeglądu kluczowych narzędzi AI dostępnych na rynku (stan na kwiecień 2025). Omawiamy funkcjonalności, modele językowe, unikalne cechy i typowe zastosowania popularnych platform, aby ułatwić wybór odpowiedniego narzędzia do konkretnych zadań, szczególnie w marketingu i SEO.

*   **Link do lekcji na platformie:** [Obejrzyj lekcję na SensAI Academy](https://learn.sensai.academy/next/public/lesson/254)
*   **Notatka z lekcji:** [./Lekcja_Podstawowe_Narzedzia_AI/Notatka_z_lekcji.md](./Lekcja_Podstawowe_Narzedzia_AI/Notatka_z_lekcji.md) - Szczegółowy opis i porównanie narzędzi Chat GPT, Perplexity, Grok, Claude, Gemini i Google AI Studio.

### Omawiane narzędzia:

*   [Chat GPT (OpenAI)](https://chat.openai.com/)
*   [Perplexity](https://www.perplexity.ai/)
*   [Grok (xAI)](https://grok.com/)
*   [Claude (Anthropic)](https://claude.ai/)
*   [Gemini (Google)](https://gemini.google.com/)
*   [Google AI Studio](https://aistudio.google.com/)

### Tabela porównawcza (stan na kwiecień 2025 wg lekcji):

| Narzędzie         | Dostawca        | Główny Cel / Zastosowanie               | Kluczowe / Unikalne Funkcje                                                                                                | Dostępne Modele (przykłady)                 | Link                                       |
| :---------------- | :-------------- | :-------------------------------------- | :------------------------------------------------------------------------------------------------------------------------- | :----------------------------------------- | :----------------------------------------- |
| **Chat GPT** | OpenAI          | Ogólne zastosowania, kod, treść        | `Canvas` (edytor), GPTs, Biblioteka, `/`-komendy, Projekty (proste)                                                         | `GPT-4o`, `GPT-4.5`, `O3`, `O4 mini`         | [chat.openai.com](https://chat.openai.com/) |
| **Perplexity** | Perplexity AI   | Wyszukiwanie i synteza aktualnej wiedzy | Cytowanie źródeł, API, Automatyczny tryb Pro, Elastyczny wybór modeli (różni dostawcy)                                       | Różni dostawcy (OpenAI, Google, Anthropic) | [perplexity.ai](https://www.perplexity.ai/) |
| **Grok** | X / xAI         | Programowanie, research, kontekst X    | `Workspaces` (separacja kontekstu), `Thinking`, Integracja z X, Dostęp przez `grok.com`                                    | `Grok`                                     | [grok.com](https://grok.com/)               |
| **Claude** | Anthropic       | Programowanie, praca projektowa        | `Artifacts` (kod live), `Projekty` (separacja + instrukcje), Integracja GitHub/Drive, Własny styl (Tone of Voice)             | `Claude 3.7 Sonnet`                        | [claude.ai](https://claude.ai/)             |
| **Gemini** | Google          | Zastosowania ogólne, integracja Google | Dostęp do `Gemini 2.5 Pro`, `Canvas`, Integracja z GSuite (wymaga zgód admina)                                              | `Gemini 2.5 Pro Experimental`              | [gemini.google.com](https://gemini.google.com/) |
| **Google AI Studio** | Google          | Zaawansowana konfiguracja, deweloperka | `Grounding` (Google Search), Kontrola parametrów (temperatura), Generowanie wideo (`Veo 2`), Wybór modeli (`Gemma`, `Gemini`) | `Gemma`, `Gemini 1.5/2.5 Pro`, `Veo 2`     | [aistudio.google.com](https://aistudio.google.com/) |

---

## Lekcja: Pozyskiwanie wiedzy i Deep Research

Ta lekcja skupia się na technikach zdobywania aktualnej wiedzy za pomocą narzędzi AI, ze szczególnym uwzględnieniem funkcji `Deep Research` / `Deep Search`. Omawiamy problem nieaktualnej wiedzy modeli LLM i pokazujemy, jak proste wyszukiwanie (np. w Perplexity) oraz zaawansowane funkcje głębokiego badania (w Chat GPT, Perplexity, Grok, Gemini) pozwalają budować kompleksową, opartą na wielu źródłach bazę wiedzy. Porównujemy działanie tych funkcji w różnych narzędziach i przedstawiamy praktyczny workflow wykorzystania wyników deep research do tworzenia i optymalizacji treści.

*   **Link do lekcji na platformie:** [Obejrzyj lekcję na SensAI Academy](https://learn.sensai.academy/next/public/lesson/256)
*   **Notatka z lekcji:** [./Lekcja_Pozyskiwanie_Wiedzy_Deep_Research/Notatka_z_lekcji.md](./Lekcja_Pozyskiwanie_Wiedzy_Deep_Research/Notatka_z_lekcji.md) - Szczegółowe omówienie i porównanie funkcji Deep Research/Search w popularnych narzędziach AI.

### Porównanie funkcji Deep Search / Research (wg lekcji):

| Narzędzie         | Nazwa Funkcji                 | Kluczowe Cechy / Proces                                     | Unikalne Dane / Możliwości          | Liczba Źródeł (Przykład "kortyzol") | Rekomendacja Prelegenta (dla Deep Research) |
| :---------------- | :---------------------------- | :---------------------------------------------------------- | :---------------------------------- | :---------------------------------- | :------------------------------------------ |
| **Chat GPT** | `Zbadaj głęboko`              | Query expansion, głęboki research (prawdopodobnie Bing)     | -                                   | ? (demo nie zadziałało)             | -                                           |
| **Perplexity** | `Badania` / `Zaaw. analiza` | Widoczny proces query expansion, iteracyjne wyszukiwanie    | Dobra wizualizacja procesu          | 39                                  | Dobry punkt startowy                     |
| **Grok** | `Deep Search`/`Deeper Search` | Query expansion, iteracyjne wyszukiwanie                    | Dostęp do danych z platformy X       | 32                                  | Dobry, zwłaszcza dla tematów z X        |
| **Gemini** | `Deep Research`               | Najbardziej rozbudowany proces, głębokie wnioskowanie (reasoning) | Największa liczba analizowanych źródeł | >73 (proces trwał)                 | **Najlepszy** pod względem kompleksowości  | 